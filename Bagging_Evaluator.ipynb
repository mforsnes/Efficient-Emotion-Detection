{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BiS2MXHIbhn",
        "outputId": "8829e195-0407-4903-f5dc-63c913f2556e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Train Images Shape: (28754, 48, 48)\n",
            "Train Labels Shape: (28754, 7)\n",
            "Test Images Shape: (7178, 48, 48)\n",
            "Test Labels Shape: (7178, 7)\n",
            "\n",
            "Train Images Data Type: float64\n",
            "Train Labels Data Type: float32\n",
            "Test Images Data Type: float64\n",
            "Test Labels Data Type: float32\n",
            "\n",
            "Train Images Min Value: 0.0\n",
            "Train Images Max Value: 1.0\n",
            "Test Images Min Value: 0.0\n",
            "Test Images Max Value: 1.0\n",
            "\n",
            "Unique Train Labels: [0. 1.]\n",
            "Unique Test Labels: [0. 1.]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from google.colab import drive\n",
        "import tensorflow as tf\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "dataset_path = '/content/drive/MyDrive/data/'\n",
        "\n",
        "train_images = np.load(dataset_path + 'train_images.npy')\n",
        "train_labels = np.load(dataset_path + 'train_labels.npy')\n",
        "test_images = np.load(dataset_path + 'test_images.npy')\n",
        "test_labels = np.load(dataset_path + 'test_labels.npy')\n",
        "\n",
        "print(\"Train Images Shape:\", train_images.shape)\n",
        "print(\"Train Labels Shape:\", train_labels.shape)\n",
        "print(\"Test Images Shape:\", test_images.shape)\n",
        "print(\"Test Labels Shape:\", test_labels.shape)\n",
        "\n",
        "print(\"\\nTrain Images Data Type:\", train_images.dtype)\n",
        "print(\"Train Labels Data Type:\", train_labels.dtype)\n",
        "print(\"Test Images Data Type:\", test_images.dtype)\n",
        "print(\"Test Labels Data Type:\", test_labels.dtype)\n",
        "\n",
        "print(\"\\nTrain Images Min Value:\", np.min(train_images))\n",
        "print(\"Train Images Max Value:\", np.max(train_images))\n",
        "print(\"Test Images Min Value:\", np.min(test_images))\n",
        "print(\"Test Images Max Value:\", np.max(test_images))\n",
        "\n",
        "print(\"\\nUnique Train Labels:\", np.unique(train_labels))\n",
        "print(\"Unique Test Labels:\", np.unique(test_labels))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the TFLite models\n",
        "model_path = '/content/drive/MyDrive/models/'\n",
        "num_models = 5\n",
        "models = []\n",
        "\n",
        "for i in range(num_models):\n",
        "    model_name = f'emotion_detection_model_{i+1}.tflite'\n",
        "    model_file = model_path + model_name\n",
        "    interpreter = tf.lite.Interpreter(model_path=model_file)\n",
        "    interpreter.allocate_tensors()\n",
        "    models.append(interpreter)\n",
        "\n",
        "#Get input and output details for the models\n",
        "input_details = models[0].get_input_details()\n",
        "output_details = models[0].get_output_details()\n",
        "\n",
        "#Evaluate the ensemble performance\n",
        "ensemble_predictions = []\n",
        "\n",
        "for image in test_images:\n",
        "    predictions = []\n",
        "    for model in models:\n",
        "        # Reshape the input tensor to match the expected shape\n",
        "        input_shape = input_details[0]['shape']\n",
        "        input_data = image.reshape(input_shape)\n",
        "\n",
        "        model.set_tensor(input_details[0]['index'], input_data.astype(np.float32))\n",
        "        model.invoke()\n",
        "        prediction = model.get_tensor(output_details[0]['index'])\n",
        "        predictions.append(prediction)\n",
        "\n",
        "    ensemble_prediction = np.mean(predictions, axis=0)\n",
        "    ensemble_predictions.append(np.argmax(ensemble_prediction))\n",
        "\n",
        "ensemble_predictions = np.array(ensemble_predictions)\n",
        "print(f\"Shape of ensemble_predictions array: {ensemble_predictions.shape}\")\n",
        "accuracy = np.mean(ensemble_predictions == np.argmax(test_labels, axis=1))\n",
        "\n",
        "print(f\"\\nEnsemble Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-rbKV5AIfLA",
        "outputId": "8e90bcfa-6794-4178-9867-d62f40c7f666"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of ensemble_predictions array: (7178,)\n",
            "\n",
            "Ensemble Accuracy: 0.6819\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the TFLite models\n",
        "model_path = '/content/drive/MyDrive/models/'\n",
        "num_models = 5\n",
        "models = []\n",
        "\n",
        "for i in range(num_models):\n",
        "    model_name = f'emotion_detection_model_{i+1}.tflite'\n",
        "    model_file = model_path + model_name\n",
        "    interpreter = tf.lite.Interpreter(model_path=model_file)\n",
        "    interpreter.allocate_tensors()\n",
        "    models.append(interpreter)\n",
        "\n",
        "\n",
        "#Evaluate the ensemble performance\n",
        "train_ensemble_features = []\n",
        "test_ensemble_features = []\n",
        "\n",
        "#Extract features from the training set\n",
        "for image in train_images:\n",
        "    train_predictions = []\n",
        "    for model in models:\n",
        "        input_shape = input_details[0]['shape']\n",
        "        input_data = image.reshape(input_shape)\n",
        "        model.set_tensor(input_details[0]['index'], input_data.astype(np.float32))\n",
        "        model.invoke()\n",
        "        prediction = model.get_tensor(output_details[0]['index'])\n",
        "        train_predictions.append(tuple(prediction.flatten()))\n",
        "    train_ensemble_features.append(tuple(train_predictions))\n",
        "\n",
        "#Extract features from the test set\n",
        "for image in test_images:\n",
        "    test_predictions = []\n",
        "    for model in models:\n",
        "        input_shape = input_details[0]['shape']\n",
        "        input_data = image.reshape(input_shape)\n",
        "        model.set_tensor(input_details[0]['index'], input_data.astype(np.float32))\n",
        "        model.invoke()\n",
        "        prediction = model.get_tensor(output_details[0]['index'])\n",
        "        test_predictions.append(tuple(prediction.flatten()))\n",
        "    test_ensemble_features.append(tuple(test_predictions))\n",
        "\n"
      ],
      "metadata": {
        "id": "6OwUA7MsNtGf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "gbdt = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
        "gbdt.fit(train_ensemble_features, np.argmax(train_labels, axis=1))\n",
        "\n",
        "#Evaluate the ensemble performance\n",
        "ensemble_predictions = gbdt.predict(test_ensemble_features)\n",
        "accuracy = np.mean(ensemble_predictions == np.argmax(test_labels, axis=1))\n",
        "\n",
        "print(f\"\\nEnsemble Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSCJW_nalkyQ",
        "outputId": "c77f447b-aa6c-42af-f841-d2984d5d090c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Ensemble Accuracy: 0.6864\n"
          ]
        }
      ]
    }
  ]
}